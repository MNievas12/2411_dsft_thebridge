{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "En el vasto universo de Star Wars, imagina que estás analizando las estrellas para predecir el destino de las galaxias. Usas un telescopio sofisticado, un modelo predictivo increíblemente fino, llamado \"The Jedi's Eye.\" Este regulador se ha entrenado con innumerables datos de galaxias pasadas, reconociendo patrones exactos de estrellas y planetas, desde la formación de sistemas estelares hasta el destino final de las civilizaciones.\n",
      "\n",
      "Ahora, imagina que 'The Jedi's Eye' ha sido entrenado en una sola estrella peculiar: una estrella similar a la Estrella Decepción, famosa por sus extrañas oscilaciones y misterios. Con el tiempo, 'The Jedi's Eye' se vuelve increíblemente hábil para predecir lo que sucede en esa estrella particular, podemos decir que ha sido \"condicionado\" a detectar cada oscilación, cada anomalía con exquisito detalle y precisión.\n",
      "\n",
      "Sin embargo, cuanto más confías en 'The Jedi's Eye' para analizar otras estrellas, más decepcionantes son las predicciones. Pues ha confundido un patrón singular de la Estrella Decepción con un comportamiento universal. ¿Por qué? Porque 'The Jedi's Eye' ha sobreajustado los datos, enfocándose en los detalles finos de una sola estrella a expensas de captar la imprevisible verdad sobre el universo más amplio.\n",
      "\n",
      "Así como 'The Jedi's Eye' cae en la trampa del sobreajuste al convertirse en un maestro de una estrella, pero un novato de las complejidades del cosmos, el sobreajuste en el aprendizaje automático ocurre cuando un modelo es demasiado específico para el conjunto de datos de entrenamiento. Definitivamente captura el mauling de los datos de entrenamiento, pero falla cuando se enfrenta a nuevos datos, prediciendo erráticamente\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "client = InferenceClient(api_key=\"\")\n",
    "\n",
    "messages = [\n",
    "\t{\n",
    "\t\t\"role\": \"user\",\n",
    "\t\t\"content\": \"Constrúyeme una metáfora para explicarme el overfitting con Star Wars\"\n",
    "\t}\n",
    "]\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"microsoft/Phi-3.5-mini-instruct\", \n",
    "\tmessages=messages, \n",
    "\tmax_tokens=500\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
