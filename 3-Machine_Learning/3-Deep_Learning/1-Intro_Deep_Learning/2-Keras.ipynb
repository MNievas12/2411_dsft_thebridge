{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "Librería para programar redes neuronales de una manera más sencilla que con TensorFlow. Keras se encuentra en una capa de abstracción por encima de TensorFlow.\n",
    "\n",
    "[Documentación](https://keras.io/guides/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install keras"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Empezamos importando librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos de mnist. No vamos a tratar imagenes con redes convolucionales (perdemos la estructura espacial 2D). Todos los pixeles se convertirán en un vector de 28x28 features independientes, que serán las entradas del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogemos las imágenes de los dígitos asi como el conjunto de train y test\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos dimensiones del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "60.000 imagenes de 28x28 pixeles\n",
    "'''\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "60.000 imágenes de 28x28 pixeles. Vamos a representar una de ellas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_2516\\3096108358.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[0], cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cada imagen se compone de 28x28 pixeles, y cada pixel representa una escala de grises que va del 0 al 255. Siendo 0 el blanco y 255 negro.\n",
    "\n",
    "¿Se te ocurre alguna manera de normalizar los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5019607843137255"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "128/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "255/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13066062"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n",
       "        0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n",
       "        0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.11764706, 0.14117648,\n",
       "        0.36862746, 0.6039216 , 0.6666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.88235295, 0.6745098 ,\n",
       "        0.99215686, 0.9490196 , 0.7647059 , 0.2509804 , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.19215687, 0.93333334, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.9843137 , 0.3647059 , 0.32156864,\n",
       "        0.32156864, 0.21960784, 0.15294118, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.07058824, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7764706 ,\n",
       "        0.7137255 , 0.96862745, 0.94509804, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.3137255 , 0.6117647 ,\n",
       "        0.41960785, 0.99215686, 0.99215686, 0.8039216 , 0.04313726,\n",
       "        0.        , 0.16862746, 0.6039216 , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.05490196,\n",
       "        0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.54509807, 0.99215686, 0.74509805, 0.00784314,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.04313726, 0.74509805, 0.99215686, 0.27450982,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.13725491, 0.94509804, 0.88235295,\n",
       "        0.627451  , 0.42352942, 0.00392157, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.31764707, 0.9411765 ,\n",
       "        0.99215686, 0.99215686, 0.46666667, 0.09803922, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n",
       "        0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.0627451 , 0.3647059 , 0.9882353 , 0.99215686, 0.73333335,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.9764706 , 0.99215686, 0.9764706 ,\n",
       "        0.2509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.18039216,\n",
       "        0.50980395, 0.7176471 , 0.99215686, 0.99215686, 0.8117647 ,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.15294118, 0.5803922 , 0.8980392 ,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.98039216, 0.7137255 ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.09019608, 0.25882354,\n",
       "        0.8352941 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.7764706 , 0.31764707, 0.00784314, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.67058825, 0.85882354, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7647059 , 0.3137255 ,\n",
       "        0.03529412, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.21568628,\n",
       "        0.6745098 , 0.8862745 , 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.95686275, 0.52156866, 0.04313726, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.53333336,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.83137256, 0.5294118 ,\n",
       "        0.5176471 , 0.0627451 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Comprobamos la normalización\n",
    "'''\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Guardamos datos para validación. Estos datos se usarán durante el entrenamiento. Otra opción es decirle a keras en la etapa de entrenamiento que reserve un X % de los datos para validar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "\n",
    "X_train = X_train[:-10000]\n",
    "y_train = y_train[:-10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos la arquitectura de la red neuronal. Se va a componer de:\n",
    "* **Sequential**: API para iniciar la red neuronal. No cuenta como capa.\n",
    "* **Flatten**: capa de entrada. Necesita un vector unidimensional. Como tenemos imágenes, esta capa aplana las imagenes (2D) en 1D.\n",
    "* **Dense**: es una hidden layer. Se compondrá de `n` neuronas y de una función de activación que se aplicará a todas las neuronas de la capa.\n",
    "\n",
    "Recuerda que es un problema de clasificación multiclase (10 clases) y que por tanto la última capa se compondrá de tantas neuronas como clases tengas.\n",
    "\n",
    "En cuanto a las funciones de activación es recomendable usar relu en las hidden layer, que tarda menos en entrenar, mientras que la ultima (output) suele ser una softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "\n",
    "# Capa entrada\n",
    "model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 300,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Hidden layer\n",
    "model.add(keras.layers.Dense(units = 100,\n",
    "                            activation='relu'))\n",
    "\n",
    "# Capa salida\n",
    "model.add(keras.layers.Dense(units = 10,\n",
    "                            activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otra manera de declarar la red neuronal\n",
    "capas = [\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(units = 300, activation='relu'),\n",
    "    keras.layers.Dense(units = 100, activation='relu'),\n",
    "    keras.layers.Dense(units = 10, activation='softmax')\n",
    "]\n",
    "\n",
    "model = keras.models.Sequential(capas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver las capas, y acceder a sus elementos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.src.layers.reshaping.flatten.Flatten object at 0x0000021F1C253E90>\n"
     ]
    }
   ],
   "source": [
    "print(model.layers[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver los pesos de las capas sin entrenar, porque los inicializa aleatoriamente. Los bias los inicializa a 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden1 = model.layers[1]\n",
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.07000935, -0.01570813,  0.05609965, ...,  0.05186507,\n",
       "         0.0039544 , -0.03760503],\n",
       "       [-0.0374433 ,  0.02414865, -0.04913577, ..., -0.00071819,\n",
       "        -0.07389734, -0.07403124],\n",
       "       [ 0.01045132, -0.02342552, -0.01363755, ..., -0.03862363,\n",
       "         0.07259874,  0.06267877],\n",
       "       ...,\n",
       "       [ 0.05183624,  0.03152754, -0.06924748, ..., -0.00107355,\n",
       "         0.05507182, -0.02244285],\n",
       "       [-0.04077723, -0.0498422 , -0.03065461, ..., -0.05667526,\n",
       "        -0.05628294, -0.03612458],\n",
       "       [ 0.05347902, -0.07288817,  0.03784343, ..., -0.03681912,\n",
       "         0.01385988, -0.05467883]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300*784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235200"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(biases)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos la configuración de ejecución... el compile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = keras.optimizers.SGD(),\n",
    "    loss = keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics = [keras.metrics.SparseCategoricalAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalente\n",
    "model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    loss = \"sparse_categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_3 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 300)               235500    \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 100)               30100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "784 * 300 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235500\n"
     ]
    }
   ],
   "source": [
    "# 1º neurona de la 1º hidden layer\n",
    "# y = a + w1*x1 + w2*x2 + .... wn*xn\n",
    "# a es el intercepto llamado bias\n",
    "# wn es cada uno de los pesos que va a ir actualizando con el backpropagation\n",
    "# n es 784\n",
    "# En la 1º hidden layer tenemos 784 pesos por cada neurona, al tener 300, tenemos un total de:\n",
    "print(784*300 + 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "235500"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 784 + 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30100"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "300 * 100 + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1010"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "100 * 10 + 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos el modelo. Usamos los datos de entrenamiento. El batch_size es la cantidad de muestras que utiliza el SGD, y las epochs son las iteraciones que realiza en el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 28, 28)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390.625"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50000/128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "391/391 [==============================] - 4s 7ms/step - loss: 1.2354 - accuracy: 0.6847 - val_loss: 0.6057 - val_accuracy: 0.8564\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.5212 - accuracy: 0.8643 - val_loss: 0.3996 - val_accuracy: 0.8981\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.4013 - accuracy: 0.8896 - val_loss: 0.3365 - val_accuracy: 0.9069\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3512 - accuracy: 0.9013 - val_loss: 0.3046 - val_accuracy: 0.9143\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.3211 - accuracy: 0.9091 - val_loss: 0.2844 - val_accuracy: 0.9193\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 4s 10ms/step - loss: 0.2998 - accuracy: 0.9152 - val_loss: 0.2681 - val_accuracy: 0.9236\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2827 - accuracy: 0.9197 - val_loss: 0.2559 - val_accuracy: 0.9273\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2686 - accuracy: 0.9242 - val_loss: 0.2443 - val_accuracy: 0.9311\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2564 - accuracy: 0.9273 - val_loss: 0.2353 - val_accuracy: 0.9321\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2453 - accuracy: 0.9309 - val_loss: 0.2264 - val_accuracy: 0.9363\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.2351 - accuracy: 0.9333 - val_loss: 0.2181 - val_accuracy: 0.9395\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2262 - accuracy: 0.9359 - val_loss: 0.2124 - val_accuracy: 0.9417\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.2180 - accuracy: 0.9388 - val_loss: 0.2062 - val_accuracy: 0.9430\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.2099 - accuracy: 0.9406 - val_loss: 0.1977 - val_accuracy: 0.9451\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.2028 - accuracy: 0.9428 - val_loss: 0.1936 - val_accuracy: 0.9462\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1961 - accuracy: 0.9433 - val_loss: 0.1874 - val_accuracy: 0.9498\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1895 - accuracy: 0.9462 - val_loss: 0.1819 - val_accuracy: 0.9508\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1837 - accuracy: 0.9474 - val_loss: 0.1789 - val_accuracy: 0.9517\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1783 - accuracy: 0.9486 - val_loss: 0.1732 - val_accuracy: 0.9524\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1729 - accuracy: 0.9505 - val_loss: 0.1685 - val_accuracy: 0.9542\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1678 - accuracy: 0.9519 - val_loss: 0.1647 - val_accuracy: 0.9541\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1631 - accuracy: 0.9531 - val_loss: 0.1613 - val_accuracy: 0.9556\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1584 - accuracy: 0.9546 - val_loss: 0.1577 - val_accuracy: 0.9558\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 4s 11ms/step - loss: 0.1542 - accuracy: 0.9559 - val_loss: 0.1551 - val_accuracy: 0.9575\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1500 - accuracy: 0.9568 - val_loss: 0.1513 - val_accuracy: 0.9588\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 4s 9ms/step - loss: 0.1460 - accuracy: 0.9583 - val_loss: 0.1485 - val_accuracy: 0.9590\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1423 - accuracy: 0.9593 - val_loss: 0.1473 - val_accuracy: 0.9591\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1387 - accuracy: 0.9605 - val_loss: 0.1438 - val_accuracy: 0.9603\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1352 - accuracy: 0.9618 - val_loss: 0.1417 - val_accuracy: 0.9612\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1319 - accuracy: 0.9625 - val_loss: 0.1398 - val_accuracy: 0.9613\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1286 - accuracy: 0.9636 - val_loss: 0.1359 - val_accuracy: 0.9616\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1256 - accuracy: 0.9646 - val_loss: 0.1337 - val_accuracy: 0.9622\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1227 - accuracy: 0.9655 - val_loss: 0.1328 - val_accuracy: 0.9623\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1198 - accuracy: 0.9661 - val_loss: 0.1292 - val_accuracy: 0.9629\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 3s 9ms/step - loss: 0.1170 - accuracy: 0.9669 - val_loss: 0.1294 - val_accuracy: 0.9646\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1144 - accuracy: 0.9679 - val_loss: 0.1279 - val_accuracy: 0.9643\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1118 - accuracy: 0.9681 - val_loss: 0.1267 - val_accuracy: 0.9643\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1094 - accuracy: 0.9692 - val_loss: 0.1241 - val_accuracy: 0.9668\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1069 - accuracy: 0.9700 - val_loss: 0.1229 - val_accuracy: 0.9663\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.1046 - accuracy: 0.9704 - val_loss: 0.1194 - val_accuracy: 0.9670\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1024 - accuracy: 0.9714 - val_loss: 0.1187 - val_accuracy: 0.9679\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.1002 - accuracy: 0.9721 - val_loss: 0.1178 - val_accuracy: 0.9670\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0981 - accuracy: 0.9726 - val_loss: 0.1167 - val_accuracy: 0.9677\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0962 - accuracy: 0.9729 - val_loss: 0.1162 - val_accuracy: 0.9683\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0942 - accuracy: 0.9737 - val_loss: 0.1141 - val_accuracy: 0.9686\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0921 - accuracy: 0.9743 - val_loss: 0.1124 - val_accuracy: 0.9683\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0904 - accuracy: 0.9746 - val_loss: 0.1113 - val_accuracy: 0.9692\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 0.0885 - accuracy: 0.9754 - val_loss: 0.1101 - val_accuracy: 0.9686\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0868 - accuracy: 0.9759 - val_loss: 0.1091 - val_accuracy: 0.9689\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 3s 8ms/step - loss: 0.0850 - accuracy: 0.9762 - val_loss: 0.1086 - val_accuracy: 0.9699\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 128,\n",
    "    epochs = 50,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos reentrenar el modelo. No empieza de nuevo, sino que retoma el entrenamiento anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0843 - accuracy: 0.9765 - val_loss: 0.1071 - val_accuracy: 0.9695\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0812 - accuracy: 0.9775 - val_loss: 0.1055 - val_accuracy: 0.9697\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0784 - accuracy: 0.9788 - val_loss: 0.1028 - val_accuracy: 0.9708\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0751 - accuracy: 0.9793 - val_loss: 0.1009 - val_accuracy: 0.9711\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0726 - accuracy: 0.9804 - val_loss: 0.1006 - val_accuracy: 0.9711\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0701 - accuracy: 0.9810 - val_loss: 0.0986 - val_accuracy: 0.9714\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0678 - accuracy: 0.9817 - val_loss: 0.0971 - val_accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.0651 - accuracy: 0.9830 - val_loss: 0.0949 - val_accuracy: 0.9732\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0629 - accuracy: 0.9835 - val_loss: 0.0945 - val_accuracy: 0.9732\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 6ms/step - loss: 0.0610 - accuracy: 0.9841 - val_loss: 0.0930 - val_accuracy: 0.9738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x21f1d4eb590>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size = 64,\n",
    "    epochs = 10,\n",
    "    validation_data = (X_val, y_val) # validation_split = 0.1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veamos el histórico del entrenamiento, para poder representarlo posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [1.2353726625442505, 0.5211768746376038, 0.4012887477874756, 0.35121262073516846, 0.3211060166358948, 0.2998276650905609, 0.2827205955982208, 0.2686437666416168, 0.25638362765312195, 0.24533064663410187, 0.23514188826084137, 0.22615736722946167, 0.217967689037323, 0.20991000533103943, 0.2028186321258545, 0.19609487056732178, 0.1895434707403183, 0.1837456226348877, 0.1783130019903183, 0.17288483679294586, 0.16783970594406128, 0.1631193608045578, 0.15839903056621552, 0.1541978120803833, 0.15001195669174194, 0.1460249125957489, 0.14229816198349, 0.13867753744125366, 0.13519218564033508, 0.13187257945537567, 0.12856869399547577, 0.12555593252182007, 0.12269985675811768, 0.11979465931653976, 0.11700628697872162, 0.11440829932689667, 0.11176930367946625, 0.10939221829175949, 0.10686624050140381, 0.10460074990987778, 0.10236592590808868, 0.10019351541996002, 0.09808506816625595, 0.09615372121334076, 0.09419214725494385, 0.09214089810848236, 0.0903773307800293, 0.08850029110908508, 0.08681311458349228, 0.08504068106412888], 'accuracy': [0.6846799850463867, 0.8643199801445007, 0.8895999789237976, 0.9012799859046936, 0.9091200232505798, 0.9151800274848938, 0.9196599721908569, 0.9242200255393982, 0.927299976348877, 0.9309399724006653, 0.9333000183105469, 0.935920000076294, 0.9387800097465515, 0.9406200051307678, 0.9427599906921387, 0.943340003490448, 0.946179986000061, 0.9474400281906128, 0.9486200213432312, 0.9504600167274475, 0.9518600106239319, 0.9531199932098389, 0.9545599818229675, 0.9559199810028076, 0.956820011138916, 0.9583399891853333, 0.9592599868774414, 0.9605200290679932, 0.9617599844932556, 0.9625200033187866, 0.9636200070381165, 0.9646000266075134, 0.9654600024223328, 0.9661399722099304, 0.9668999910354614, 0.9678800106048584, 0.9681400060653687, 0.9691600203514099, 0.9700000286102295, 0.9703999757766724, 0.9713799953460693, 0.9720600247383118, 0.972599983215332, 0.9729200005531311, 0.9737200140953064, 0.9743000268936157, 0.9745799899101257, 0.9753999710083008, 0.9759200215339661, 0.9761999845504761], 'val_loss': [0.6056858897209167, 0.39964559674263, 0.33645710349082947, 0.3046162724494934, 0.28439590334892273, 0.26809659600257874, 0.25585389137268066, 0.24427998065948486, 0.23532146215438843, 0.22637858986854553, 0.21814465522766113, 0.21236906945705414, 0.20620879530906677, 0.19769595563411713, 0.19358153641223907, 0.18738852441310883, 0.1819344460964203, 0.17889079451560974, 0.17319561541080475, 0.1685396283864975, 0.16468240320682526, 0.1613467037677765, 0.15767215192317963, 0.15511280298233032, 0.15127485990524292, 0.14851024746894836, 0.14729972183704376, 0.14382101595401764, 0.14173977077007294, 0.13983950018882751, 0.1358960121870041, 0.1337069869041443, 0.13281428813934326, 0.12924420833587646, 0.12940213084220886, 0.1279030293226242, 0.12667979300022125, 0.1240684911608696, 0.12288042902946472, 0.11938653886318207, 0.11871341615915298, 0.11784035712480545, 0.11674428731203079, 0.11624454706907272, 0.11412522196769714, 0.11240341514348984, 0.11129128187894821, 0.1101142093539238, 0.10913856327533722, 0.1086164191365242], 'val_accuracy': [0.8564000129699707, 0.8981000185012817, 0.9068999886512756, 0.9143000245094299, 0.9193000197410583, 0.9236000180244446, 0.927299976348877, 0.9311000108718872, 0.9320999979972839, 0.9362999796867371, 0.9394999742507935, 0.9416999816894531, 0.9430000185966492, 0.9451000094413757, 0.9462000131607056, 0.9498000144958496, 0.9508000016212463, 0.95169997215271, 0.9524000287055969, 0.954200029373169, 0.9541000127792358, 0.9556000232696533, 0.9557999968528748, 0.9574999809265137, 0.9588000178337097, 0.9589999914169312, 0.9591000080108643, 0.9603000283241272, 0.9611999988555908, 0.9613000154495239, 0.9616000056266785, 0.9621999859809875, 0.9623000025749207, 0.9628999829292297, 0.9646000266075134, 0.9642999768257141, 0.9642999768257141, 0.9667999744415283, 0.9663000106811523, 0.9670000076293945, 0.9678999781608582, 0.9670000076293945, 0.9677000045776367, 0.9682999849319458, 0.9685999751091003, 0.9682999849319458, 0.9692000150680542, 0.9685999751091003, 0.9689000248908997, 0.9699000120162964]}\n"
     ]
    }
   ],
   "source": [
    "# print(history.params)\n",
    "# print(history.epoch)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.2353726625442505,\n",
       "  0.5211768746376038,\n",
       "  0.4012887477874756,\n",
       "  0.35121262073516846,\n",
       "  0.3211060166358948,\n",
       "  0.2998276650905609,\n",
       "  0.2827205955982208,\n",
       "  0.2686437666416168,\n",
       "  0.25638362765312195,\n",
       "  0.24533064663410187,\n",
       "  0.23514188826084137,\n",
       "  0.22615736722946167,\n",
       "  0.217967689037323,\n",
       "  0.20991000533103943,\n",
       "  0.2028186321258545,\n",
       "  0.19609487056732178,\n",
       "  0.1895434707403183,\n",
       "  0.1837456226348877,\n",
       "  0.1783130019903183,\n",
       "  0.17288483679294586,\n",
       "  0.16783970594406128,\n",
       "  0.1631193608045578,\n",
       "  0.15839903056621552,\n",
       "  0.1541978120803833,\n",
       "  0.15001195669174194,\n",
       "  0.1460249125957489,\n",
       "  0.14229816198349,\n",
       "  0.13867753744125366,\n",
       "  0.13519218564033508,\n",
       "  0.13187257945537567,\n",
       "  0.12856869399547577,\n",
       "  0.12555593252182007,\n",
       "  0.12269985675811768,\n",
       "  0.11979465931653976,\n",
       "  0.11700628697872162,\n",
       "  0.11440829932689667,\n",
       "  0.11176930367946625,\n",
       "  0.10939221829175949,\n",
       "  0.10686624050140381,\n",
       "  0.10460074990987778,\n",
       "  0.10236592590808868,\n",
       "  0.10019351541996002,\n",
       "  0.09808506816625595,\n",
       "  0.09615372121334076,\n",
       "  0.09419214725494385,\n",
       "  0.09214089810848236,\n",
       "  0.0903773307800293,\n",
       "  0.08850029110908508,\n",
       "  0.08681311458349228,\n",
       "  0.08504068106412888],\n",
       " 'accuracy': [0.6846799850463867,\n",
       "  0.8643199801445007,\n",
       "  0.8895999789237976,\n",
       "  0.9012799859046936,\n",
       "  0.9091200232505798,\n",
       "  0.9151800274848938,\n",
       "  0.9196599721908569,\n",
       "  0.9242200255393982,\n",
       "  0.927299976348877,\n",
       "  0.9309399724006653,\n",
       "  0.9333000183105469,\n",
       "  0.935920000076294,\n",
       "  0.9387800097465515,\n",
       "  0.9406200051307678,\n",
       "  0.9427599906921387,\n",
       "  0.943340003490448,\n",
       "  0.946179986000061,\n",
       "  0.9474400281906128,\n",
       "  0.9486200213432312,\n",
       "  0.9504600167274475,\n",
       "  0.9518600106239319,\n",
       "  0.9531199932098389,\n",
       "  0.9545599818229675,\n",
       "  0.9559199810028076,\n",
       "  0.956820011138916,\n",
       "  0.9583399891853333,\n",
       "  0.9592599868774414,\n",
       "  0.9605200290679932,\n",
       "  0.9617599844932556,\n",
       "  0.9625200033187866,\n",
       "  0.9636200070381165,\n",
       "  0.9646000266075134,\n",
       "  0.9654600024223328,\n",
       "  0.9661399722099304,\n",
       "  0.9668999910354614,\n",
       "  0.9678800106048584,\n",
       "  0.9681400060653687,\n",
       "  0.9691600203514099,\n",
       "  0.9700000286102295,\n",
       "  0.9703999757766724,\n",
       "  0.9713799953460693,\n",
       "  0.9720600247383118,\n",
       "  0.972599983215332,\n",
       "  0.9729200005531311,\n",
       "  0.9737200140953064,\n",
       "  0.9743000268936157,\n",
       "  0.9745799899101257,\n",
       "  0.9753999710083008,\n",
       "  0.9759200215339661,\n",
       "  0.9761999845504761],\n",
       " 'val_loss': [0.6056858897209167,\n",
       "  0.39964559674263,\n",
       "  0.33645710349082947,\n",
       "  0.3046162724494934,\n",
       "  0.28439590334892273,\n",
       "  0.26809659600257874,\n",
       "  0.25585389137268066,\n",
       "  0.24427998065948486,\n",
       "  0.23532146215438843,\n",
       "  0.22637858986854553,\n",
       "  0.21814465522766113,\n",
       "  0.21236906945705414,\n",
       "  0.20620879530906677,\n",
       "  0.19769595563411713,\n",
       "  0.19358153641223907,\n",
       "  0.18738852441310883,\n",
       "  0.1819344460964203,\n",
       "  0.17889079451560974,\n",
       "  0.17319561541080475,\n",
       "  0.1685396283864975,\n",
       "  0.16468240320682526,\n",
       "  0.1613467037677765,\n",
       "  0.15767215192317963,\n",
       "  0.15511280298233032,\n",
       "  0.15127485990524292,\n",
       "  0.14851024746894836,\n",
       "  0.14729972183704376,\n",
       "  0.14382101595401764,\n",
       "  0.14173977077007294,\n",
       "  0.13983950018882751,\n",
       "  0.1358960121870041,\n",
       "  0.1337069869041443,\n",
       "  0.13281428813934326,\n",
       "  0.12924420833587646,\n",
       "  0.12940213084220886,\n",
       "  0.1279030293226242,\n",
       "  0.12667979300022125,\n",
       "  0.1240684911608696,\n",
       "  0.12288042902946472,\n",
       "  0.11938653886318207,\n",
       "  0.11871341615915298,\n",
       "  0.11784035712480545,\n",
       "  0.11674428731203079,\n",
       "  0.11624454706907272,\n",
       "  0.11412522196769714,\n",
       "  0.11240341514348984,\n",
       "  0.11129128187894821,\n",
       "  0.1101142093539238,\n",
       "  0.10913856327533722,\n",
       "  0.1086164191365242],\n",
       " 'val_accuracy': [0.8564000129699707,\n",
       "  0.8981000185012817,\n",
       "  0.9068999886512756,\n",
       "  0.9143000245094299,\n",
       "  0.9193000197410583,\n",
       "  0.9236000180244446,\n",
       "  0.927299976348877,\n",
       "  0.9311000108718872,\n",
       "  0.9320999979972839,\n",
       "  0.9362999796867371,\n",
       "  0.9394999742507935,\n",
       "  0.9416999816894531,\n",
       "  0.9430000185966492,\n",
       "  0.9451000094413757,\n",
       "  0.9462000131607056,\n",
       "  0.9498000144958496,\n",
       "  0.9508000016212463,\n",
       "  0.95169997215271,\n",
       "  0.9524000287055969,\n",
       "  0.954200029373169,\n",
       "  0.9541000127792358,\n",
       "  0.9556000232696533,\n",
       "  0.9557999968528748,\n",
       "  0.9574999809265137,\n",
       "  0.9588000178337097,\n",
       "  0.9589999914169312,\n",
       "  0.9591000080108643,\n",
       "  0.9603000283241272,\n",
       "  0.9611999988555908,\n",
       "  0.9613000154495239,\n",
       "  0.9616000056266785,\n",
       "  0.9621999859809875,\n",
       "  0.9623000025749207,\n",
       "  0.9628999829292297,\n",
       "  0.9646000266075134,\n",
       "  0.9642999768257141,\n",
       "  0.9642999768257141,\n",
       "  0.9667999744415283,\n",
       "  0.9663000106811523,\n",
       "  0.9670000076293945,\n",
       "  0.9678999781608582,\n",
       "  0.9670000076293945,\n",
       "  0.9677000045776367,\n",
       "  0.9682999849319458,\n",
       "  0.9685999751091003,\n",
       "  0.9682999849319458,\n",
       "  0.9692000150680542,\n",
       "  0.9685999751091003,\n",
       "  0.9689000248908997,\n",
       "  0.9699000120162964]}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.235373</td>\n",
       "      <td>0.68468</td>\n",
       "      <td>0.605686</td>\n",
       "      <td>0.8564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.521177</td>\n",
       "      <td>0.86432</td>\n",
       "      <td>0.399646</td>\n",
       "      <td>0.8981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.401289</td>\n",
       "      <td>0.88960</td>\n",
       "      <td>0.336457</td>\n",
       "      <td>0.9069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.351213</td>\n",
       "      <td>0.90128</td>\n",
       "      <td>0.304616</td>\n",
       "      <td>0.9143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.321106</td>\n",
       "      <td>0.90912</td>\n",
       "      <td>0.284396</td>\n",
       "      <td>0.9193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.299828</td>\n",
       "      <td>0.91518</td>\n",
       "      <td>0.268097</td>\n",
       "      <td>0.9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.282721</td>\n",
       "      <td>0.91966</td>\n",
       "      <td>0.255854</td>\n",
       "      <td>0.9273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.268644</td>\n",
       "      <td>0.92422</td>\n",
       "      <td>0.244280</td>\n",
       "      <td>0.9311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.256384</td>\n",
       "      <td>0.92730</td>\n",
       "      <td>0.235321</td>\n",
       "      <td>0.9321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.245331</td>\n",
       "      <td>0.93094</td>\n",
       "      <td>0.226379</td>\n",
       "      <td>0.9363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.235142</td>\n",
       "      <td>0.93330</td>\n",
       "      <td>0.218145</td>\n",
       "      <td>0.9395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.226157</td>\n",
       "      <td>0.93592</td>\n",
       "      <td>0.212369</td>\n",
       "      <td>0.9417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.217968</td>\n",
       "      <td>0.93878</td>\n",
       "      <td>0.206209</td>\n",
       "      <td>0.9430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.209910</td>\n",
       "      <td>0.94062</td>\n",
       "      <td>0.197696</td>\n",
       "      <td>0.9451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.202819</td>\n",
       "      <td>0.94276</td>\n",
       "      <td>0.193582</td>\n",
       "      <td>0.9462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.196095</td>\n",
       "      <td>0.94334</td>\n",
       "      <td>0.187389</td>\n",
       "      <td>0.9498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.189543</td>\n",
       "      <td>0.94618</td>\n",
       "      <td>0.181934</td>\n",
       "      <td>0.9508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.183746</td>\n",
       "      <td>0.94744</td>\n",
       "      <td>0.178891</td>\n",
       "      <td>0.9517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.178313</td>\n",
       "      <td>0.94862</td>\n",
       "      <td>0.173196</td>\n",
       "      <td>0.9524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.172885</td>\n",
       "      <td>0.95046</td>\n",
       "      <td>0.168540</td>\n",
       "      <td>0.9542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.167840</td>\n",
       "      <td>0.95186</td>\n",
       "      <td>0.164682</td>\n",
       "      <td>0.9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.163119</td>\n",
       "      <td>0.95312</td>\n",
       "      <td>0.161347</td>\n",
       "      <td>0.9556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.158399</td>\n",
       "      <td>0.95456</td>\n",
       "      <td>0.157672</td>\n",
       "      <td>0.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.154198</td>\n",
       "      <td>0.95592</td>\n",
       "      <td>0.155113</td>\n",
       "      <td>0.9575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.150012</td>\n",
       "      <td>0.95682</td>\n",
       "      <td>0.151275</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.146025</td>\n",
       "      <td>0.95834</td>\n",
       "      <td>0.148510</td>\n",
       "      <td>0.9590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.142298</td>\n",
       "      <td>0.95926</td>\n",
       "      <td>0.147300</td>\n",
       "      <td>0.9591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.138678</td>\n",
       "      <td>0.96052</td>\n",
       "      <td>0.143821</td>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.135192</td>\n",
       "      <td>0.96176</td>\n",
       "      <td>0.141740</td>\n",
       "      <td>0.9612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.131873</td>\n",
       "      <td>0.96252</td>\n",
       "      <td>0.139840</td>\n",
       "      <td>0.9613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.128569</td>\n",
       "      <td>0.96362</td>\n",
       "      <td>0.135896</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.125556</td>\n",
       "      <td>0.96460</td>\n",
       "      <td>0.133707</td>\n",
       "      <td>0.9622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.122700</td>\n",
       "      <td>0.96546</td>\n",
       "      <td>0.132814</td>\n",
       "      <td>0.9623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.119795</td>\n",
       "      <td>0.96614</td>\n",
       "      <td>0.129244</td>\n",
       "      <td>0.9629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.117006</td>\n",
       "      <td>0.96690</td>\n",
       "      <td>0.129402</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.114408</td>\n",
       "      <td>0.96788</td>\n",
       "      <td>0.127903</td>\n",
       "      <td>0.9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.111769</td>\n",
       "      <td>0.96814</td>\n",
       "      <td>0.126680</td>\n",
       "      <td>0.9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.109392</td>\n",
       "      <td>0.96916</td>\n",
       "      <td>0.124068</td>\n",
       "      <td>0.9668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.106866</td>\n",
       "      <td>0.97000</td>\n",
       "      <td>0.122880</td>\n",
       "      <td>0.9663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.104601</td>\n",
       "      <td>0.97040</td>\n",
       "      <td>0.119387</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.102366</td>\n",
       "      <td>0.97138</td>\n",
       "      <td>0.118713</td>\n",
       "      <td>0.9679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.100194</td>\n",
       "      <td>0.97206</td>\n",
       "      <td>0.117840</td>\n",
       "      <td>0.9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.098085</td>\n",
       "      <td>0.97260</td>\n",
       "      <td>0.116744</td>\n",
       "      <td>0.9677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.096154</td>\n",
       "      <td>0.97292</td>\n",
       "      <td>0.116245</td>\n",
       "      <td>0.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.094192</td>\n",
       "      <td>0.97372</td>\n",
       "      <td>0.114125</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.092141</td>\n",
       "      <td>0.97430</td>\n",
       "      <td>0.112403</td>\n",
       "      <td>0.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.090377</td>\n",
       "      <td>0.97458</td>\n",
       "      <td>0.111291</td>\n",
       "      <td>0.9692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.97540</td>\n",
       "      <td>0.110114</td>\n",
       "      <td>0.9686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.086813</td>\n",
       "      <td>0.97592</td>\n",
       "      <td>0.109139</td>\n",
       "      <td>0.9689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.085041</td>\n",
       "      <td>0.97620</td>\n",
       "      <td>0.108616</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        loss  accuracy  val_loss  val_accuracy\n",
       "0   1.235373   0.68468  0.605686        0.8564\n",
       "1   0.521177   0.86432  0.399646        0.8981\n",
       "2   0.401289   0.88960  0.336457        0.9069\n",
       "3   0.351213   0.90128  0.304616        0.9143\n",
       "4   0.321106   0.90912  0.284396        0.9193\n",
       "5   0.299828   0.91518  0.268097        0.9236\n",
       "6   0.282721   0.91966  0.255854        0.9273\n",
       "7   0.268644   0.92422  0.244280        0.9311\n",
       "8   0.256384   0.92730  0.235321        0.9321\n",
       "9   0.245331   0.93094  0.226379        0.9363\n",
       "10  0.235142   0.93330  0.218145        0.9395\n",
       "11  0.226157   0.93592  0.212369        0.9417\n",
       "12  0.217968   0.93878  0.206209        0.9430\n",
       "13  0.209910   0.94062  0.197696        0.9451\n",
       "14  0.202819   0.94276  0.193582        0.9462\n",
       "15  0.196095   0.94334  0.187389        0.9498\n",
       "16  0.189543   0.94618  0.181934        0.9508\n",
       "17  0.183746   0.94744  0.178891        0.9517\n",
       "18  0.178313   0.94862  0.173196        0.9524\n",
       "19  0.172885   0.95046  0.168540        0.9542\n",
       "20  0.167840   0.95186  0.164682        0.9541\n",
       "21  0.163119   0.95312  0.161347        0.9556\n",
       "22  0.158399   0.95456  0.157672        0.9558\n",
       "23  0.154198   0.95592  0.155113        0.9575\n",
       "24  0.150012   0.95682  0.151275        0.9588\n",
       "25  0.146025   0.95834  0.148510        0.9590\n",
       "26  0.142298   0.95926  0.147300        0.9591\n",
       "27  0.138678   0.96052  0.143821        0.9603\n",
       "28  0.135192   0.96176  0.141740        0.9612\n",
       "29  0.131873   0.96252  0.139840        0.9613\n",
       "30  0.128569   0.96362  0.135896        0.9616\n",
       "31  0.125556   0.96460  0.133707        0.9622\n",
       "32  0.122700   0.96546  0.132814        0.9623\n",
       "33  0.119795   0.96614  0.129244        0.9629\n",
       "34  0.117006   0.96690  0.129402        0.9646\n",
       "35  0.114408   0.96788  0.127903        0.9643\n",
       "36  0.111769   0.96814  0.126680        0.9643\n",
       "37  0.109392   0.96916  0.124068        0.9668\n",
       "38  0.106866   0.97000  0.122880        0.9663\n",
       "39  0.104601   0.97040  0.119387        0.9670\n",
       "40  0.102366   0.97138  0.118713        0.9679\n",
       "41  0.100194   0.97206  0.117840        0.9670\n",
       "42  0.098085   0.97260  0.116744        0.9677\n",
       "43  0.096154   0.97292  0.116245        0.9683\n",
       "44  0.094192   0.97372  0.114125        0.9686\n",
       "45  0.092141   0.97430  0.112403        0.9683\n",
       "46  0.090377   0.97458  0.111291        0.9692\n",
       "47  0.088500   0.97540  0.110114        0.9686\n",
       "48  0.086813   0.97592  0.109139        0.9689\n",
       "49  0.085041   0.97620  0.108616        0.9699"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1) # set the vertical range to [0-1]\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si el modelo no ha ido bien, prueba a cambiar el learning rate, cambia de optimizador y después prueba a cambiar capas, neuronas y funciones de activación.\n",
    "\n",
    "Ya tenemos el modelo entrenado. Probémoslo con test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9731\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08990992605686188, 0.9731000065803528]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_2516\\1468152043.py:2: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cogemos el primero\n",
    "plt.imshow(X_test[0].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.32941177, 0.7254902 , 0.62352943, 0.5921569 ,\n",
       "         0.23529412, 0.14117648, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.87058824, 0.99607843, 0.99607843, 0.99607843,\n",
       "         0.99607843, 0.94509804, 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "         0.6666667 , 0.20392157, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2627451 , 0.44705883, 0.28235295, 0.44705883,\n",
       "         0.6392157 , 0.8901961 , 0.99607843, 0.88235295, 0.99607843,\n",
       "         0.99607843, 0.99607843, 0.98039216, 0.8980392 , 0.99607843,\n",
       "         0.99607843, 0.54901963, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "         0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "         0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.3254902 , 0.99215686,\n",
       "         0.81960785, 0.07058824, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.08627451, 0.9137255 , 1.        ,\n",
       "         0.3254902 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.5058824 , 0.99607843, 0.93333334,\n",
       "         0.17254902, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23137255, 0.9764706 , 0.99607843, 0.24313726,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.03529412, 0.8039216 , 0.972549  , 0.22745098, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.49411765, 0.99607843, 0.7137255 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.29411766,\n",
       "         0.9843137 , 0.9411765 , 0.22352941, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.07450981, 0.8666667 ,\n",
       "         0.99607843, 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "         0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.14901961, 0.99607843, 0.99607843,\n",
       "         0.3019608 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.12156863, 0.8784314 , 0.99607843, 0.4509804 ,\n",
       "         0.00392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.52156866, 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23921569, 0.9490196 , 0.99607843, 0.99607843, 0.20392157,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.4745098 , 0.99607843, 0.8117647 , 0.07058824, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        ]]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 126ms/step\n",
      "(1, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.   , 0.   , 0.002, 0.   , 0.   , 0.   , 0.998, 0.   ,\n",
       "        0.   ]], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(X_test[:1])\n",
    "print(predictions.shape)\n",
    "np.round(predictions,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "312.5"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape[0]/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Miguel Angel\\AppData\\Local\\Temp\\ipykernel_2516\\4029188365.py:1: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[1].reshape(28,28), cmap=plt.cm.get_cmap('Greys'));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 964,    0,    2,    1,    1,    3,    4,    1,    3,    1],\n",
       "       [   0, 1121,    2,    1,    0,    2,    3,    1,    5,    0],\n",
       "       [   4,    1, 1006,    4,    3,    0,    1,    5,    8,    0],\n",
       "       [   0,    0,    3,  991,    0,    3,    0,    3,    9,    1],\n",
       "       [   2,    0,    5,    0,  959,    0,    1,    2,    1,   12],\n",
       "       [   6,    1,    0,    9,    2,  856,    7,    1,    8,    2],\n",
       "       [   5,    3,    0,    1,    3,    9,  933,    1,    3,    0],\n",
       "       [   2,   10,   11,    5,    1,    0,    0,  990,    2,    7],\n",
       "       [   3,    0,    6,    5,    3,    3,    4,    3,  946,    1],\n",
       "       [   5,    7,    2,    9,    9,    1,    1,    5,    5,  965]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_matrix(y_test, model.predict(X_test).argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.98       980\n",
      "         1.0       0.98      0.99      0.98      1135\n",
      "         2.0       0.97      0.97      0.97      1032\n",
      "         3.0       0.97      0.98      0.97      1010\n",
      "         4.0       0.98      0.98      0.98       982\n",
      "         5.0       0.98      0.96      0.97       892\n",
      "         6.0       0.98      0.97      0.98       958\n",
      "         7.0       0.98      0.96      0.97      1028\n",
      "         8.0       0.96      0.97      0.96       974\n",
      "         9.0       0.98      0.96      0.97      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, model.predict(X_test).argmax(axis=1)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema de regresión\n",
    "Veamos un ejemplo de cómo aplicar una red neuronal de TensorFlow a un problema de regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  target  \n",
       "0    -122.23   4.526  \n",
       "1    -122.22   3.585  \n",
       "2    -122.24   3.521  \n",
       "3    -122.25   3.413  \n",
       "4    -122.25   3.422  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargamos datos\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "df = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "df['target'] = housing['target']\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divimos en train, test y validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(housing.data,\n",
    "                                                              housing.target)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full,\n",
    "                                                      y_train_full)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11610, 8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Montamos el modelo. Simplemente se compondrá de una hidden layer, a la que le configuramos una capa previa de entrada de 8 neuronas (las features).\n",
    "\n",
    "Se trata de un modelo de regresión, por lo que la capa de salida es una única neurona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "362.8125"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11610/32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8,)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.7947 - val_loss: 8.4268\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.5248 - val_loss: 0.5846\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4280 - val_loss: 0.4311\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4319 - val_loss: 0.4779\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.4378 - val_loss: 0.4251\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4270 - val_loss: 0.4126\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3930 - val_loss: 0.5682\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.4114 - val_loss: 0.4129\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3837 - val_loss: 0.4849\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3808 - val_loss: 0.3847\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3726 - val_loss: 0.4250\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3708 - val_loss: 0.3988\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3677 - val_loss: 0.3832\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3660 - val_loss: 0.3987\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3628 - val_loss: 0.3834\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3607 - val_loss: 0.3969\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3625 - val_loss: 0.3750\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3744 - val_loss: 0.4123\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3577 - val_loss: 0.3731\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 1s 4ms/step - loss: 0.3559 - val_loss: 0.3760\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation = 'relu',\n",
    "                      input_shape = X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(loss = \"mean_squared_error\",\n",
    "             optimizer = \"sgd\")\n",
    "\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs = 20,\n",
    "                   validation_data = (X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8*30 + 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 30)                270       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 301 (1.18 KB)\n",
      "Trainable params: 301 (1.18 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 2ms/step - loss: 0.3663\n",
      "0.3662945330142975\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(X_test, y_test)\n",
    "print(mse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.6921997 ],\n",
       "       [3.0802212 ],\n",
       "       [0.79800755],\n",
       "       [2.9747157 ],\n",
       "       [4.5573835 ]], dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test[:5])\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guardar modelo\n",
    "Para guardar el modelo, en el formato de Keras (HDF5). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo volvemos a cargar\n",
    "model = keras.models.load_model(\"my_keras_model.h5\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "Son funciones predefinidas de Keras a aplicar durante el entrenamiento\n",
    "Por ejemplo, `ModelCheckpoint` sirve para que el modelo se vaya guardando tras cada epoch. Así no perdemos el progreso en caso de que decidamos interrumpir el entrenamiento. El callback recibe como argumento el nombre del objeto donde queremos que se guarde el modelo entrenado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3548\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3531\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3520\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3526\n",
      "Epoch 5/30\n",
      "352/363 [============================>.] - ETA: 0s - loss: 0.3535"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[93], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m checkpoint_cb \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mModelCheckpoint(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallback_model.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint_cb\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\training.py:1798\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1796\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_epoch_begin(epoch)\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mcatch_stop_iteration():\n\u001b[1;32m-> 1798\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39msteps():\n\u001b[0;32m   1799\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1800\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1801\u001b[0m             epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1804\u001b[0m             _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1805\u001b[0m         ):\n\u001b[0;32m   1806\u001b[0m             callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1411\u001b[0m, in \u001b[0;36mDataHandler.steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_insufficient_data:  \u001b[38;5;66;03m# Set by `catch_stop_iteration`.\u001b[39;00m\n\u001b[0;32m   1410\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m-> 1411\u001b[0m original_spe \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_steps_per_execution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m   1412\u001b[0m can_run_full_execution \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1413\u001b[0m     original_spe \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1414\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1415\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m original_spe\n\u001b[0;32m   1416\u001b[0m )\n\u001b[0;32m   1418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_run_full_execution:\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:689\u001b[0m, in \u001b[0;36mBaseResourceVariable.numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnumpy\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    690\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[0;32m    691\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy() is only available when eager execution is enabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:839\u001b[0m, in \u001b[0;36mBaseResourceVariable.read_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs an op which reads the value of this variable.\u001b[39;00m\n\u001b[0;32m    831\u001b[0m \n\u001b[0;32m    832\u001b[0m \u001b[38;5;124;03mShould be used when there are multiple reads, or when it is desirable to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    836\u001b[0m \u001b[38;5;124;03m  The value of the variable.\u001b[39;00m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRead\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 839\u001b[0m   value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_variable_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;66;03m# Return an identity so it can get placed on whatever device the context\u001b[39;00m\n\u001b[0;32m    841\u001b[0m \u001b[38;5;66;03m# specifies instead of the device where the variable is.\u001b[39;00m\n\u001b[0;32m    842\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m array_ops\u001b[38;5;241m.\u001b[39midentity(value)\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:818\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    816\u001b[0m       result \u001b[38;5;241m=\u001b[39m read_and_set_handle(no_copy)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mread_and_set_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_copy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    820\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m    821\u001b[0m   \u001b[38;5;66;03m# Note that if a control flow context is active the input of the read op\u001b[39;00m\n\u001b[0;32m    822\u001b[0m   \u001b[38;5;66;03m# might not actually be the handle. This line bypasses it.\u001b[39;00m\n\u001b[0;32m    823\u001b[0m   record\u001b[38;5;241m.\u001b[39mrecord_operation(\n\u001b[0;32m    824\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReadVariableOp\u001b[39m\u001b[38;5;124m\"\u001b[39m, [result], [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle],\n\u001b[0;32m    825\u001b[0m       backward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x],\n\u001b[0;32m    826\u001b[0m       forward_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: [x])\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:808\u001b[0m, in \u001b[0;36mBaseResourceVariable._read_variable_op.<locals>.read_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    806\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m no_copy \u001b[38;5;129;01mand\u001b[39;00m forward_compat\u001b[38;5;241m.\u001b[39mforward_compatible(\u001b[38;5;241m2022\u001b[39m, \u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m    807\u001b[0m   gen_resource_variable_ops\u001b[38;5;241m.\u001b[39mdisable_copy_on_read(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m--> 808\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    809\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    810\u001b[0m _maybe_set_handle_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, result)\n\u001b[0;32m    811\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\Miguel Angel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:535\u001b[0m, in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    534\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 535\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    536\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mReadVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    538\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"callback_model.h5\")\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=30,\n",
    "                   callbacks = [checkpoint_cb])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "Interrumpe el entrenamiento cuando no ve progreso en el set de validación. Para ello tiene en cuenta un numero de epochs llamado `patience`. Se puede combinar con el callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "363/363 [==============================] - 1s 3ms/step - loss: 0.3488 - val_loss: 0.3694\n",
      "Epoch 2/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3472 - val_loss: 0.3906\n",
      "Epoch 3/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3469 - val_loss: 0.3856\n",
      "Epoch 4/50\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.3456 - val_loss: 0.3892\n"
     ]
    }
   ],
   "source": [
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3)\n",
    "history = model.fit(X_train,\n",
    "                   y_train,\n",
    "                   epochs=50,\n",
    "                   validation_data = (X_valid, y_valid),\n",
    "                   callbacks = [early_stopping_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
